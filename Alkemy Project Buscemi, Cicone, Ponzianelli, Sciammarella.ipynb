{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8da4548",
   "metadata": {},
   "source": [
    "# Alkemy project - Maria Cicone, Andrea Buscemi, Alessandro Ponzianelli, Carlamaria Sciammarella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f01539f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyspark\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03445e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Alkemy App\").enableHiveSupport().getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df8bd4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Creating a database\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS sales_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2407e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if the database exists\n",
    "v=spark.sql(\"show databases\")\n",
    "v.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f814f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creating schema for the tables\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "stock_schema=StructType([\n",
    "        StructField(\"stock_date\", DateType(), nullable=False),\n",
    "        StructField(\"product_id\", StringType(), nullable=False),\n",
    "        StructField(\"total_stock\", IntegerType(), nullable=False) ])\n",
    "\n",
    "clicks_schema= StructType([\n",
    "        StructField(\"date\", TimestampType(), nullable=False),\n",
    "        StructField(\"seller\", StringType(), nullable=False),\n",
    "        StructField(\"position\", IntegerType(), nullable=False),\n",
    "        StructField(\"price_max\", DoubleType(), nullable=False),\n",
    "        StructField(\"price_min\", DoubleType(), nullable=False),\n",
    "        StructField(\"price\", DoubleType(), nullable=False),\n",
    "        StructField(\"type\", StringType(), nullable=False),\n",
    "        StructField(\"product_id\", StringType(), nullable=False) ])\n",
    "\n",
    "sellers_schema= StructType([\n",
    "        StructField(\"seller_id\", StringType(), nullable=False),\n",
    "        StructField(\"seller_name\", StringType(), nullable=False)])\n",
    "\n",
    "catalog_schema= StructType([\n",
    "        StructField(\"product_id\", StringType(), nullable=False),\n",
    "        StructField(\"coded_cat1\", StringType(), nullable=False),\n",
    "        StructField(\"coded_cat2\", StringType(), nullable=False),\n",
    "        StructField(\"coded_cat3\", StringType(), nullable=False),\n",
    "        StructField(\"coded_brand\", StringType(), nullable=False),\n",
    "        StructField(\"coded_name\", StringType(), nullable=False)])\n",
    "\n",
    "competitor_schema= StructType([\n",
    "        StructField(\"comp_date\", DateType(), nullable=False),\n",
    "        StructField(\"seller_id\", StringType(), nullable=False),\n",
    "        StructField(\"product_id\", StringType(), nullable=False),\n",
    "        StructField(\"price\", DoubleType(), nullable=False) ])\n",
    "\n",
    "sales_schema= StructType([\n",
    "        StructField(\"sale_date\", DateType(), nullable=False),\n",
    "        StructField(\"product_id\", StringType(), nullable=False),\n",
    "        StructField(\"quantity\", IntegerType(), nullable=False),\n",
    "        StructField(\"sales_price_tax\", DoubleType(), nullable=False),\n",
    "        StructField(\"regular_price_tax\", DoubleType(), nullable=False),\n",
    "        StructField(\"sales_price\", DoubleType(), nullable=False),\n",
    "        StructField(\"regular_price\", DoubleType(), nullable=False),\n",
    "        StructField(\"purchase_price\", DoubleType(), nullable=False)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reading the datasets\n",
    "stock = spark.read.option(\"header\",True).schema(stock_schema).csv(\"stock.csv\")\n",
    "clicks_b = spark.read.option(\"header\",True).schema(clicks_schema).csv(\"clicks_bidding.csv\")\n",
    "clicks_r = spark.read.option(\"header\",True).schema(clicks_schema).csv(\"clicks_regular.csv\")\n",
    "sellers = spark.read.option(\"header\",True).schema(sellers_schema).csv(\"sellers_list.csv\")\n",
    "catalog = spark.read.option(\"header\",True).schema(catalog_schema).csv(\"product_catalog.csv\")\n",
    "competitor = spark.read.option(\"header\",True).schema(competitor_schema).csv(\"prices_competitor.csv\")\n",
    "sales = spark.read.option(\"header\",True).schema(sales_schema).csv(\"sales_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5346939",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding seller_id specification to our client\n",
    "from pyspark.sql.functions import lit\n",
    "sales=sales.withColumn(\"seller_id\", lit(24))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58c0e1",
   "metadata": {},
   "source": [
    "## Cleaning the dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ef2fe",
   "metadata": {},
   "source": [
    "### Prices_competitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prices_competitor\n",
    "\n",
    "##Checking for missing values, duplicates or outliers in the prices set\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "competitor.filter(competitor.price.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitor.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitor.distinct().count()\n",
    "####There are no absolute duplicates, even if prices are set multiple times in the same day by the same seller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a190a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitor.filter(competitor.price== 0).show()  ##Remove 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de47056",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Looking for outliers by comparing mean vs median\n",
    "out1= competitor.groupBy([\"product_id\", \"seller_id\"]).agg(mean('price').alias(\"mean\"), percentile_approx(\"price\", 0.5).alias(\"median\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a6ca2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.scatter(data_frame=out1.toPandas(), x=\"mean\", y=\"median\", trendline=\"ols\", color_discrete_sequence=['royalblue'], title=\"Price Set by Competitors - Mean vs Median Per Product ID and Seller\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed946964",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Finding the outlier\n",
    "out1.filter(out1.median == 107936).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5e42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier=competitor.filter((out1.seller_id == 41) & (out1.product_id == 164429))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb3fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(outlier.toPandas(), x=\"price\", title=\"Distribution of price - Product 164429/Seller 41\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier.sort(outlier.price.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier.filter(outlier.comp_date==\"2021-04-02\").show() ###It is likely a typo, there is an additional 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e56341",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Correcting the typo\n",
    "competitor = competitor.withColumn(\"price\", when((competitor.price == 1040290) & (competitor.product_id==164429),104290).otherwise(competitor.price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Dropping rows with 0 price values\n",
    "competitor=competitor.filter(competitor.price!=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5922e5",
   "metadata": {},
   "source": [
    "### Sales_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05494186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales\n",
    "sales.filter(sales.regular_price.isNull()).count() ###0\n",
    "sales.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dcd11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.distinct().count() ###No duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e256a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.filter(sales.regular_price== 0).show() ##Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49256fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Looking for outliers - Regular Price\n",
    "out2= sales.groupBy(\"product_id\").agg(mean('regular_price').alias(\"mean\"), percentile_approx(\"regular_price\", 0.5).alias(\"median\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae62ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data_frame=out2.toPandas(), x=\"mean\", y=\"median\", trendline=\"ols\", color_discrete_sequence=['royalblue'], title=\"Regular Price - Mean vs Median Per Product ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.filter(sales.sales_price.isNull()).count() ##0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b285c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.filter(sales.sales_price== 0).show() #Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Looking for outliers --- sales_price\n",
    "out3= sales.groupBy(\"product_id\").agg(mean('sales_price').alias(\"mean\"), percentile_approx(\"sales_price\", 0.5).alias(\"median\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data_frame=out3.toPandas(), x=\"mean\", y=\"median\", trendline=\"ols\", color_discrete_sequence=['royalblue'], title=\"Sale Price - Mean vs Median Per Product ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df753adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Finding the hypothetical outlier\n",
    "out3.filter(out3.median == 291658).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.filter(sales.purchase_price.isNull()).count() ##0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9077b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.filter(sales.purchase_price== 0).show() ##Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Looking for outliers ---purchase price\n",
    "out4= sales.groupBy(\"product_id\").agg(mean('purchase_price').alias(\"mean\"), percentile_approx(\"purchase_price\", 0.5).alias(\"median\"))\n",
    "px.scatter(data_frame=out4.toPandas(), x=\"mean\", y=\"median\", trendline=\"ols\", color_discrete_sequence=['royalblue'], title=\"Purchase Price - Mean vs Median Per Product ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26018630",
   "metadata": {},
   "outputs": [],
   "source": [
    "out4.filter(out4.median>272000 ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696cccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_sales=sales.filter(sales.product_id ==163731)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_sales.show() ###The sales_price reacted to changes in the purchase_price, therefore there is no outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3eb53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Dropping variables we are not going to use\n",
    "column_sales=[\"regular_price_tax\", \"sales_price_tax\"]\n",
    "sales=sales.drop(*column_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89366f11",
   "metadata": {},
   "source": [
    "### Clicks_regular and clicks_bidding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicks_regular\n",
    "##Missing values\n",
    "clicks_r.filter(clicks_r.price.isNull()).count() ## 1093244  ###DROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a8d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_r.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f92b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_r.distinct().count()\n",
    "###We decided not to drop the duplicates as the user_id is not mentioned and it is possible for different users to click on the same insertion at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67000c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Missing values\n",
    "clicks_b.filter(clicks_b.price.isNull()).count() ###0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fbf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_b.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_b.distinct().count() ###We decided to keep the duplicates for the same reason we mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Dropping the price column from the click dataframes, as it has a lot of missing values and it is redundant, since price is listed in the prices_competitor dataframe\n",
    "##Dropping price_max and price_min, as well as the position, as they are inconsistent and not useful for our analysis\n",
    "click_columns=[\"price\", \"price_max\", \"price_min\", \"position\"]\n",
    "clicks_b=clicks_b.drop(*click_columns)\n",
    "clicks_r=clicks_r.drop(*click_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca80800",
   "metadata": {},
   "source": [
    "### Inserting the tables in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f847e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting the dataframes into tables of our database ###Overwrite mode to rewrite the files in case of updates\n",
    "catalog.write.mode('overwrite').saveAsTable(\"sales_db.product_catalog\")\n",
    "sales.write.mode('overwrite').saveAsTable(\"sales_db.sales_data\")\n",
    "sellers.write.mode('overwrite').saveAsTable(\"sales_db.sellers_list\")\n",
    "competitor.write.mode('overwrite').saveAsTable(\"sales_db.prices_competitor\")\n",
    "stock.write.mode('overwrite').saveAsTable(\"sales_db.stock\")\n",
    "clicks_b.write.mode('overwrite').saveAsTable(\"sales_db.clicks\")\n",
    "clicks_r.write.mode('append').saveAsTable(\"sales_db.clicks\") ##Append values to an already existing table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14477e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Showing the tables of the database\n",
    "b=spark.sql(\"show tables from sales_db\")\n",
    "b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d19cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checking if data was correctly inserted into the tables\n",
    "df1=spark.sql(\"select * from sales_db.clicks a where a.type='Bidding'\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d9f74",
   "metadata": {},
   "source": [
    "### Some data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b81871",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Top 10 most clicked products\n",
    "\n",
    "top_clicks=spark.sql('''\n",
    "          SELECT a.product_id, count(*) AS n_clicks\n",
    "          FROM sales_db.clicks a\n",
    "          GROUP BY a.product_id\n",
    "          ORDER BY n_clicks desc\n",
    "          LIMIT 10\n",
    "          ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "fig_top=sns.barplot(top_clicks.toPandas(), x=\"product_id\", y=\"n_clicks\", color=\"limegreen\", order=top_clicks.toPandas().sort_values(\"n_clicks\",ascending = False).product_id)\n",
    "ple=fig_top.set_title(\"The 10 Most Clicked Products\")\n",
    "plt.ylabel(\"N° of clicks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1013943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##N of products offered per seller\n",
    "\n",
    "df_p_seller=spark.sql('''SELECT s.seller_name, count(*) AS n_products\n",
    "          FROM sales_db.sellers_list s, (SELECT a.seller_id, a.product_id, count(*) \n",
    "          FROM sales_db.prices_competitor a\n",
    "          GROUP BY a.seller_id, a.product_id\n",
    "          ) ca\n",
    "          WHERE s.seller_id=ca.seller_id\n",
    "          GROUP BY s.seller_name\n",
    "          ORDER BY n_products desc\n",
    "          ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_p_seller=sns.barplot(df_p_seller.toPandas(), x=\"seller_name\", y=\"n_products\", color=\"#A61022\", order=df_p_seller.toPandas().sort_values(\"n_products\",ascending = False).seller_name)\n",
    "ple=fig_p_seller.set_title(\"N° of products offered per competitor\")\n",
    "plt.ylabel(\"N° of products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## N of products per macrocategory\n",
    "\n",
    "p_per_cat= spark.sql('''SELECT a.coded_cat1, count(*) AS n_products\n",
    "          FROM sales_db.product_catalog a\n",
    "          GROUP BY a.coded_cat1''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab91c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_p_cat=sns.barplot(p_per_cat.toPandas(), x=\"coded_cat1\", y=\"n_products\", color=\"royalblue\", order=p_per_cat.toPandas().sort_values(\"n_products\",ascending = False).coded_cat1)\n",
    "ple=fig_p_cat.set_title(\"N° of products per macro-category\")\n",
    "plt.ylabel(\"N° of products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeacbf16",
   "metadata": {},
   "source": [
    "### TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY CAT_1 1676\n",
    "\n",
    "df_1676=spark.sql(\"SELECT * FROM (SELECT p.product_id, pc.coded_cat1, count(distinct p.seller_id) as n_sellers, count(p.product_id) as n_date FROM sales_db.prices_competitor p, sales_db.product_catalog pc WHERE p.product_id=pc.product_id GROUP BY p.product_id, pc.coded_cat1 ORDER BY n_sellers desc) a WHERE a.n_sellers=9 AND a.coded_cat1=1676 ORDER BY a.n_date desc LIMIT 1\")\n",
    "df_1676.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ae896",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PRODUCT 139545\n",
    "df_p1=spark.sql(\"SELECT p.comp_date as date, p.seller_id, p.product_id, p.price FROM sales_db.prices_competitor p WHERE p.product_id=139545 ORDER BY date\")\n",
    "df_p1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_p1=px.line(data_frame=df_p1.toPandas(), x=\"date\", y=\"price\", color=\"seller_id\", title=\"Price History - Product 139545\")\n",
    "graph_p1.show()\n",
    "\n",
    "###By filtering sellers and timeframe on the graphs, a strong relationship among sellers n° 48,26,24 and 180 can be identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f472396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY CAT_1 2259\n",
    "df_2259=spark.sql(\"SELECT * FROM (SELECT p.product_id, pc.coded_cat1, count( distinct p.seller_id) as n_sellers, count(p.product_id) as n_date FROM sales_db.prices_competitor p, sales_db.product_catalog pc WHERE p.product_id=pc.product_id GROUP BY p.product_id, pc.coded_cat1 ORDER BY n_sellers desc) a WHERE a.n_sellers=9 AND a.coded_cat1=2259 ORDER BY a.n_date desc LIMIT 1\")\n",
    "df_2259.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PRODUCT 139038\n",
    "df_p2=spark.sql(\"SELECT p.comp_date as date, p.seller_id, p.product_id, p.price FROM sales_db.prices_competitor p WHERE p.product_id=139038 ORDER BY date\")\n",
    "df_p2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403397d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_p2=px.line(data_frame=df_p2.toPandas(), x=\"date\", y=\"price\", color=\"seller_id\", title=\"Price History - Product 139038\")\n",
    "graph_p2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b0f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY CAT_1 1375\n",
    "df_1375=spark.sql(\"SELECT * FROM (SELECT p.product_id, pc.coded_cat1, count( distinct p.seller_id) as n_sellers, count(p.product_id) as n_date FROM sales_db.prices_competitor p, sales_db.product_catalog pc WHERE p.product_id=pc.product_id GROUP BY p.product_id, pc.coded_cat1 ORDER BY n_sellers desc) a WHERE a.n_sellers=9 AND a.coded_cat1=1375 ORDER BY a.n_date desc LIMIT 1\")\n",
    "df_1375.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PRODUCT 107693\n",
    "df_p3=spark.sql(\"SELECT p.comp_date as date, p.seller_id, p.product_id, p.price FROM sales_db.prices_competitor p WHERE p.product_id=107693 ORDER BY date\")\n",
    "df_p3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fdb626",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_p3=px.line(data_frame=df_p3.toPandas(), x=\"date\", y=\"price\", color=\"seller_id\", title=\"Price History - Product 107693\")\n",
    "graph_p3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66164923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY CAT_1 1776  ##EMPTY QUERY\n",
    "df_1776=spark.sql(\"SELECT * FROM (SELECT p.product_id, pc.coded_cat1, count( distinct p.seller_id) as n_sellers, count(p.product_id) as n_date FROM sales_db.prices_competitor p, sales_db.product_catalog pc WHERE p.product_id=pc.product_id GROUP BY p.product_id, pc.coded_cat1 ORDER BY n_sellers desc) a WHERE a.n_sellers=9 AND a.coded_cat1=1776 ORDER BY a.n_date desc LIMIT 1\")\n",
    "df_1776.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY CAT_1 1127\n",
    "df_1127=spark.sql(\"SELECT * FROM (SELECT p.product_id, pc.coded_cat1, count( distinct p.seller_id) as n_sellers, count(p.product_id) as n_date FROM sales_db.prices_competitor p, sales_db.product_catalog pc WHERE p.product_id=pc.product_id GROUP BY p.product_id, pc.coded_cat1 ORDER BY n_sellers desc) a WHERE a.n_sellers=9 AND a.coded_cat1=1127 ORDER BY a.n_date desc LIMIT 1\")\n",
    "df_1127.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0fd7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PRODUCT 133528\n",
    "df_p4=spark.sql(\"SELECT p.comp_date as date, p.seller_id, p.product_id, p.price FROM sales_db.prices_competitor p WHERE p.product_id=133528 ORDER BY date\")\n",
    "df_p4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103195d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_p4=px.line(data_frame=df_p3.toPandas(), x=\"date\", y=\"price\", color=\"seller_id\", title=\"Price History - Product 133528\")\n",
    "graph_p4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca85b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY CAT_1 1163\n",
    "df_1163=spark.sql(\"SELECT * FROM (SELECT p.product_id, pc.coded_cat1, count( distinct p.seller_id) as n_sellers, count(p.product_id) as n_date FROM sales_db.prices_competitor p, sales_db.product_catalog pc WHERE p.product_id=pc.product_id GROUP BY p.product_id, pc.coded_cat1 ORDER BY n_sellers desc) a WHERE a.n_sellers=9 AND a.coded_cat1=1163 ORDER BY a.n_date desc LIMIT 1\")\n",
    "df_1163.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e577a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRODUCT 132575\n",
    "df_p5=spark.sql(\"SELECT p.comp_date as date, p.seller_id, p.product_id, p.price FROM sales_db.prices_competitor p WHERE p.product_id=132575 ORDER BY date\")\n",
    "df_p5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_p5=px.line(data_frame=df_p5.toPandas(), x=\"date\", y=\"price\", color=\"seller_id\", title=\"Price History - Product 132575\")\n",
    "graph_p5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY CAT_1 1354\n",
    "df_1354=spark.sql(\"SELECT * FROM (SELECT p.product_id, pc.coded_cat1, count( distinct p.seller_id) as n_sellers, count(p.product_id) as n_date FROM sales_db.prices_competitor p, sales_db.product_catalog pc WHERE p.product_id=pc.product_id GROUP BY p.product_id, pc.coded_cat1 ORDER BY n_sellers desc) a WHERE a.n_sellers=9 AND a.coded_cat1=1354 ORDER BY a.n_date desc LIMIT 1\")\n",
    "df_1354.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRODUCT 148202\n",
    "df_p6=spark.sql(\"SELECT p.comp_date as date, p.seller_id, p.product_id, p.price FROM sales_db.prices_competitor p WHERE p.product_id=148202 ORDER BY date\")\n",
    "df_p6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66bdcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_p6=px.line(data_frame=df_p6.toPandas(), x=\"date\", y=\"price\", color=\"seller_id\", title=\"Price History - Product 148202\")\n",
    "graph_p6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc34c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY CAT_1 2180\n",
    "df_2180=spark.sql(\"SELECT * FROM (SELECT p.product_id, pc.coded_cat1, count( distinct p.seller_id) as n_sellers, count(p.product_id) as n_date FROM sales_db.prices_competitor p, sales_db.product_catalog pc WHERE p.product_id=pc.product_id GROUP BY p.product_id, pc.coded_cat1 ORDER BY n_sellers desc) a WHERE a.n_sellers=9 AND a.coded_cat1=2180 ORDER BY a.n_date desc LIMIT 1\")\n",
    "df_2180.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29993117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRODUCT 135173\n",
    "df_p7=spark.sql(\"SELECT p.comp_date as date, p.seller_id, p.product_id, p.price FROM sales_db.prices_competitor p WHERE p.product_id=135173 ORDER BY date\")\n",
    "df_p7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_p7=px.line(data_frame=df_p7.toPandas(), x=\"date\", y=\"price\", color=\"seller_id\", title=\"Price History - Product 135173\")\n",
    "graph_p7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecc489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY CAT_1 2880\n",
    "df_2880=spark.sql(\"SELECT * FROM (SELECT p.product_id, pc.coded_cat1, count( distinct p.seller_id) as n_sellers, count(p.product_id) as n_date FROM sales_db.prices_competitor p, sales_db.product_catalog pc WHERE p.product_id=pc.product_id GROUP BY p.product_id, pc.coded_cat1 ORDER BY n_sellers desc) a WHERE a.n_sellers=9 AND a.coded_cat1=2880 ORDER BY a.n_date desc LIMIT 1\")\n",
    "df_2880.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRODUCT 160792\n",
    "df_p8=spark.sql(\"SELECT p.comp_date as date, p.seller_id, p.product_id, p.price FROM sales_db.prices_competitor p WHERE p.product_id=160792 ORDER BY date\")\n",
    "df_p8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_p8=px.line(data_frame=df_p8.toPandas(), x=\"date\", y=\"price\", color=\"seller_id\", title=\"Price History - Product 160792\")\n",
    "graph_p8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f5927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY CAT_1 1617\n",
    "df_1617=spark.sql(\"SELECT * FROM (SELECT p.product_id, pc.coded_cat1, count( distinct p.seller_id) as n_sellers, count(p.product_id) as n_date FROM sales_db.prices_competitor p, sales_db.product_catalog pc WHERE p.product_id=pc.product_id GROUP BY p.product_id, pc.coded_cat1 ORDER BY n_sellers desc) a WHERE a.n_sellers=9 AND a.coded_cat1=1617 ORDER BY a.n_date desc LIMIT 1\")\n",
    "df_1617.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRODUCT 140647\n",
    "df_p9=spark.sql(\"SELECT p.comp_date as date, p.seller_id, p.product_id, p.price FROM sales_db.prices_competitor p WHERE p.product_id=140647 ORDER BY date\")\n",
    "df_p9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e798cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_p9=px.line(data_frame=df_p9.toPandas(), x=\"date\", y=\"price\", color=\"seller_id\", title=\"Price History - Product 140647\")\n",
    "graph_p9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496c179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY CAT_1 885\n",
    "df_885=spark.sql(\"SELECT * FROM (SELECT p.product_id, pc.coded_cat1, count( distinct p.seller_id) as n_sellers, count(p.product_id) as n_date FROM sales_db.prices_competitor p, sales_db.product_catalog pc WHERE p.product_id=pc.product_id GROUP BY p.product_id, pc.coded_cat1 ORDER BY n_sellers desc) a WHERE a.n_sellers=9 AND a.coded_cat1=885 ORDER BY a.n_date desc LIMIT 1\")\n",
    "df_885.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b02f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRODUCT 103455\n",
    "df_p10=spark.sql(\"SELECT p.comp_date as date, p.seller_id, p.product_id, p.price FROM sales_db.prices_competitor p WHERE p.product_id=103455 ORDER BY date\")\n",
    "df_p10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eca0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_p10=px.line(data_frame=df_p10.toPandas(), x=\"date\", y=\"price\", color=\"seller_id\", title=\"Price History - Product 103455\")\n",
    "graph_p10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUERY CAT_1 624\n",
    "df_624=spark.sql(\"SELECT * FROM (SELECT p.product_id, pc.coded_cat1, count( distinct p.seller_id) as n_sellers, count(p.product_id) as n_date FROM sales_db.prices_competitor p, sales_db.product_catalog pc WHERE p.product_id=pc.product_id GROUP BY p.product_id, pc.coded_cat1 ORDER BY n_sellers desc) a WHERE a.n_sellers=9 AND a.coded_cat1=624 ORDER BY a.n_date desc LIMIT 1\")\n",
    "df_624.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2127fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRODUCT 158032\n",
    "df_p11=spark.sql(\"SELECT p.comp_date as date, p.seller_id, p.product_id, p.price FROM sales_db.prices_competitor p WHERE p.product_id=158032 ORDER BY date\")\n",
    "df_p11.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_p11=px.line(data_frame=df_p11.toPandas(), x=\"date\", y=\"price\", color=\"seller_id\", title=\"Price History - Product 158032\")\n",
    "graph_p11.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c26ec1",
   "metadata": {},
   "source": [
    "### TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31ca8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Querying from clicks the number of daily clicks per product, the number of total clicks in a day, \n",
    "##the daily rank based on clicks of every product (in ascending order, so the product ranked first is the one with the fewest clicks)\n",
    "##and the rank of the day based on the total clicks compared with the number of clicks registered by the others (in ascending order)\n",
    "\n",
    "df_clicks=spark.sql(''' WITH clicks as (SELECT a.date, a.product_id, a.n_clicks, \n",
    "          SUM(a.n_clicks) OVER (PARTITION BY a.date) AS total_daily_clicks, RANK() OVER(PARTITION BY a.date ORDER BY a.n_clicks) AS asc_daily_rank\n",
    "          FROM (SELECT date(c.date) AS date, c.product_id, COUNT(c.product_id) n_clicks \n",
    "          FROM sales_db.clicks c\n",
    "          WHERE date(c.date) LIKE \"2021%\"\n",
    "          GROUP BY date(c.date), c.product_id) a)\n",
    "          SELECT cl.date, cl.product_id, cl.n_clicks, cl.total_daily_clicks, cl.asc_daily_rank, \n",
    "          DENSE_RANK() OVER(ORDER BY cl.total_daily_clicks) AS asc_rank_days\n",
    "          FROM clicks cl\n",
    "          ORDER BY cl.date, cl.n_clicks DESC ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7ec5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Scaling the ranks (0 to 1 values, the highest values correspond to the the products/days with more clicks )\n",
    "\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "##Scaling the clicks rank\n",
    "assembler = VectorAssembler(inputCols=[\"asc_daily_rank\"], outputCol=\"asc_daily_rank_vector\")\n",
    "scaler = MinMaxScaler(inputCol=\"asc_daily_rank_vector\", outputCol=\"asc_daily_rank_norm\")\n",
    "pipe = Pipeline(stages=[assembler, scaler])\n",
    "scalerM = pipe.fit(df_clicks)\n",
    "df_clicks = scalerM.transform(df_clicks).drop(\"asc_daily_rank_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f640eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Scaling the days rank\n",
    "assembler_2 = VectorAssembler(inputCols=[\"asc_rank_days\"], outputCol=\"asc_rank_days_vector\")\n",
    "scaler_2 = MinMaxScaler(inputCol=\"asc_rank_days_vector\", outputCol=\"asc_rank_days_norm\")\n",
    "pipe_2 = Pipeline(stages=[assembler_2, scaler_2])\n",
    "scalerM_2 = pipe_2.fit(df_clicks)\n",
    "df_clicks = scalerMl_2.transform(df_clicks).drop(\"asc_rank_days_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4074b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Converting the resulting vectors to arrays and then to simple floats\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "df_clicks=df_clicks.withColumn('asc_rank_days_norm', vector_to_array('asc_rank_days_norm'))\n",
    "df_clicks=df_clicks.withColumn(\"asc_rank_days_norm\",df_clicks.asc_rank_days_norm[0])\n",
    "\n",
    "df_clicks=df_clicks.withColumn('asc_daily_rank_norm', vector_to_array('asc_daily_rank_norm'))\n",
    "df_clicks=df_clicks.withColumn(\"asc_daily_rank_norm\",df_clicks.asc_daily_rank_norm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ec210",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_clicks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0aa6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Defining the popularity index function\n",
    "import math\n",
    "def popularity_index (row):\n",
    "    return math.exp(row[\"asc_daily_rank_norm\"])+ row[\"asc_rank_days_norm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Converting the pyspark dataframe into a pandas dataframe\n",
    "df_clicks_pd=df_clicks.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6119ace",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_clicks_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d62464",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Applying the popularity index function to create a new column in the dataframe\n",
    "df_clicks_pd[\"popularity_index\"]= df_clicks_pd.apply(lambda row: popularity_index(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Normalizing the index (0 to 1 values)\n",
    "from sklearn import preprocessing\n",
    "df_clicks_pd[\"popularity_index\"] = (df_clicks_pd[\"popularity_index\"] - df_clicks_pd[\"popularity_index\"].min()) / (df_clicks_pd[\"popularity_index\"].max() - df_clicks_pd[\"popularity_index\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daacec2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_clicks_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f911562",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Plotting the distribution of the index\n",
    "fig_dis=sns.histplot(data=df_clicks_pd, x=\"popularity_index\")\n",
    "dis=fig_dis.set_title(\"Popularity index distribution\")\n",
    "plt.ylabel(\"N° of products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2810f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Defining the function to divide the dates in quarters\n",
    "def t_bin(x):\n",
    "    q1 = '2021-04-01'\n",
    "    q2 = '2021-07-01'\n",
    "    q3 = '2021-10-01'\n",
    "    if x < pd.to_datetime(q1):\n",
    "        return \"Q1\"\n",
    "    elif x < pd.to_datetime(q2):\n",
    "        return \"Q2\"\n",
    "    elif x < pd.to_datetime(q3):\n",
    "        return \"Q3\"\n",
    "    else:\n",
    "        return \"Q4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd8231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the function to filter the Black Friday timeframe\n",
    "\n",
    "def blackfriday(x):\n",
    "    start = '2021-11-01'\n",
    "    end = '2021-11-30'\n",
    "    if x >= pd.to_datetime(start) and x <= pd.to_datetime(end):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b01e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the first function to a new column in the df\n",
    "df_clicks_pd[\"Qs\"] = df_clicks_pd['date'].apply(lambda row:t_bin(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the second function to a new column in the df\n",
    "df_clicks_pd[\"BlackFriday\"] = df_clicks_pd['date'].apply(lambda row:blackfriday(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb336b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Grouping the rows in order to compute the mean of each product's popularity index in the various quarters\n",
    "df_grouped = pd.DataFrame(df_clicks_pd.groupby(['product_id', 'Qs'])['popularity_index'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84917550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d5ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting the index\n",
    "df_clicks_pd_grouped = df_grouped.reset_index()\n",
    "df_clicks_pd_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sorting the rows in order to find the top 5 products by popularity in Q1 \n",
    "df_clicks_pd_grouped[df_clicks_pd_grouped[\"Qs\"]==\"Q1\"].sort_values(by=\"popularity_index\", ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sorting the rows in order to find the top 5 products by popularity in Q2\n",
    "df_clicks_pd_grouped[df_clicks_pd_grouped[\"Qs\"]==\"Q2\"].sort_values(by=\"popularity_index\", ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d9457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sorting the rows in order to find the top 5 products by popularity in Q3\n",
    "df_clicks_pd_grouped[df_clicks_pd_grouped[\"Qs\"]==\"Q3\"].sort_values(by=\"popularity_index\", ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f7b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sorting the rows in order to find the top 5 products by popularity in Q4\n",
    "df_clicks_pd_grouped[df_clicks_pd_grouped[\"Qs\"]==\"Q4\"].sort_values(by=\"popularity_index\", ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Filtering the df to select only the Black Friday timeframe\n",
    "df_black_f = df_clicks_pd[df_clicks_pd['BlackFriday'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67066b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Grouping the rows in order to compute the mean of each product's popularity index in the timeframe\n",
    "df_bf_grouped = pd.DataFrame(df_black_f.groupby('product_id')['popularity_index'].mean())\n",
    "df_bf_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007cf737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting the index\n",
    "df_black_friday= df_bf_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ad55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the rows in order to find the top 5 products by popularity during the Black Friday period\n",
    "df_black_friday=df_black_friday.sort_values(by=\"popularity_index\", ascending= False)\n",
    "df_black_friday.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea4743",
   "metadata": {},
   "outputs": [],
   "source": [
    "##spark.stop() ##Uncomment to close Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110fb223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
